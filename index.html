<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <title>TNTU AI TRAINER [Debug Mode]</title>
    <style>
        :root { --primary: #00ffcc; --bg: #111; --danger: #ff4444; }
        body { margin: 0; background: var(--bg); color: #fff; font-family: sans-serif; height: 100vh; display: flex; flex-direction: column; }
        
        #error-overlay {
            position: fixed; top: 0; left: 0; width: 100%; padding: 20px;
            background: rgba(255, 0, 0, 0.9); color: white; z-index: 9999;
            display: none; font-family: monospace; font-size: 14px; white-space: pre-wrap;
        }

        #layout { display: flex; flex: 1; overflow: hidden; }
        #viewport { flex: 1; background: #000; position: relative; display: flex; justify-content: center; align-items: center; }
        #sidebar { width: 300px; background: #222; border-left: 2px solid var(--primary); padding: 15px; display: flex; flex-direction: column; gap: 10px; }

        #cam-container { position: relative; width: 640px; height: 480px; border: 2px solid #444; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); object-fit: cover; }
        
        button {
            padding: 10px; background: #333; color: var(--primary); 
            border: 1px solid var(--primary); cursor: pointer; font-weight: bold; width: 100%;
        }
        button:hover { background: var(--primary); color: #000; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        button.recording { background: var(--danger); color: white; border-color: white; animation: pulse 1s infinite; }

        .stat { display: flex; justify-content: space-between; font-size: 12px; margin-bottom: 5px; color: #ccc; }
        
        @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
    </style>

    <!-- –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ (CDN) -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js" crossorigin="anonymous"></script>
</head>
<body>

    <!-- –ë–ª–æ–∫ –¥–ª—è –ø–æ–º–∏–ª–æ–∫ -->
    <div id="error-overlay"></div>

    <div id="layout">
        <div id="viewport">
            <div id="cam-container">
                <video id="video" playsinline></video>
                <canvas id="output"></canvas>
            </div>
        </div>

        <div id="sidebar">
            <h2 style="margin: 0 0 10px 0; color: var(--primary);">AI Trainer v2</h2>
            
            <div style="border: 1px solid #444; padding: 10px; border-radius: 5px;">
                <div class="stat"><span>0. IDLE (–°–ø–æ–∫—ñ–π)</span><span id="c0">0</span></div>
                <button onmousedown="startRec(0)" onmouseup="stopRec()">REC: IDLE</button>

                <div class="stat"><span>1. GRAB (–•–∞–ø–∞—Ç–∏)</span><span id="c1">0</span></div>
                <button onmousedown="startRec(1)" onmouseup="stopRec()">REC: GRAB</button>

                <div class="stat"><span>2. ROTATE (–û–±–µ—Ä—Ç)</span><span id="c2">0</span></div>
                <button onmousedown="startRec(2)" onmouseup="stopRec()">REC: ROTATE</button>

                <div class="stat"><span>3. ZOOM (–ú–∞—Å—à—Ç–∞–±)</span><span id="c3">0</span></div>
                <button onmousedown="startRec(3)" onmouseup="stopRec()">REC: ZOOM</button>
            </div>

            <button onclick="train()" id="btn-train" style="margin-top: 10px;">üöÄ START TRAINING</button>
            <div id="status" style="text-align: center; font-size: 12px; color: #888;">Ready</div>

            <div id="prediction" style="font-size: 20px; text-align: center; font-weight: bold; margin: 10px 0; color: #fff;">---</div>

            <button onclick="download()" id="btn-save" disabled>üíæ DOWNLOAD MODEL</button>
        </div>
    </div>

<script>
    // --- –û–ë–†–û–ë–ù–ò–ö –ü–û–ú–ò–õ–û–ö ---
    window.onerror = function(msg, url, line, col, error) {
        const div = document.getElementById('error-overlay');
        div.style.display = 'block';
        div.innerHTML += `CRITICAL ERROR:\n${msg}\nLine: ${line}\n\n–ü–æ—Ä–∞–¥–∞: –°–ø—Ä–æ–±—É–π—Ç–µ –≤—ñ–¥–∫—Ä–∏—Ç–∏ —á–µ—Ä–µ–∑ Live Server (–Ω–µ —è–∫ —Ñ–∞–π–ª).\n`;
        return false;
    };

    // --- –ü–ï–†–ï–í–Ü–†–ö–ê –ö–ê–ú–ï–†–ò ---
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error("–ë—Ä–∞—É–∑–µ—Ä –Ω–µ –º–∞—î –¥–æ—Å—Ç—É–ø—É –¥–æ –∫–∞–º–µ—Ä–∏! –Ø–∫—â–æ –≤–∏ –≤—ñ–¥–∫—Ä–∏–ª–∏ —Ü–µ —è–∫ —Ñ–∞–π–ª (file://), —Ü–µ –Ω–µ —Å–ø—Ä–∞—Ü—é—î. –ó–∞–ø—É—Å—Ç—ñ—Ç—å –ª–æ–∫–∞–ª—å–Ω–∏–π —Å–µ—Ä–≤–µ—Ä.");
    }

    // --- –ó–ú–Ü–ù–ù–Ü ---
    const VIDEO = document.getElementById('video');
    const CANVAS = document.getElementById('output');
    const CTX = CANVAS.getContext('2d');
    const CLASSES = ['Idle', 'Grab', 'Rotate', 'Zoom'];
    
    let isRecording = false;
    let currentLabel = -1;
    let data = { inputs: [], labels: [] };
    let counts = [0, 0, 0, 0];
    let model = null;
    let isTraining = false;

    // --- MEDIAPIPE ---
    const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
    });

    hands.onResults(onResults);

    // –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä–∏
    const camera = new Camera(VIDEO, {
        onFrame: async () => { await hands.send({image: VIDEO}); },
        width: 640, height: 480
    });
    camera.start().catch(e => {
        throw new Error("–ö–∞–º–µ—Ä–∞ –∑–∞–π–Ω—è—Ç–∞ –∞–±–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: " + e.message);
    });

    // --- –õ–û–ì–Ü–ö–ê –ö–ê–î–†–£ ---
    function onResults(results) {
        CTX.clearRect(0, 0, CANVAS.width, CANVAS.height);
        CTX.drawImage(results.image, 0, 0, CANVAS.width, CANVAS.height);

        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
            const lm = results.multiHandLandmarks[0];
            drawConnectors(CTX, lm, HAND_CONNECTIONS, {color: '#00ffcc', lineWidth: 2});
            drawLandmarks(CTX, lm, {color: '#ff0000', lineWidth: 1, radius: 3});

            if (isRecording) {
                record(lm);
            } else if (model && !isTraining) {
                predict(lm);
            }
        }
    }

    // --- –ù–û–†–ú–ê–õ–Ü–ó–ê–¶–Ü–Ø ---
    function processLandmarks(landmarks) {
        const wrist = landmarks[0];
        const flat = [];
        let max = 0;
        for (let p of landmarks) {
            let x = p.x - wrist.x;
            let y = p.y - wrist.y;
            let z = p.z - wrist.z;
            flat.push(x, y, z);
            max = Math.max(max, Math.abs(x), Math.abs(y), Math.abs(z));
        }
        return flat.map(v => v / (max + 1e-6));
    }

    // --- –ó–ê–ü–ò–° ---
    function startRec(id) { isRecording = true; currentLabel = id; }
    function stopRec() { isRecording = false; }
    
    function record(lm) {
        data.inputs.push(processLandmarks(lm));
        data.labels.push(currentLabel);
        counts[currentLabel]++;
        document.getElementById(`c${currentLabel}`).innerText = counts[currentLabel];
    }

    // --- –ù–ê–í–ß–ê–ù–ù–Ø ---
    async function train() {
        if (data.inputs.length < 10) { alert("–ú–∞–ª–æ –¥–∞–Ω–∏—Ö!"); return; }
        
        isTraining = true;
        document.getElementById('status').innerText = "Training...";
        
        const inputs = tf.tensor2d(data.inputs);
        const labels = tf.oneHot(tf.tensor1d(data.labels, 'int32'), 4);

        model = tf.sequential();
        model.add(tf.layers.dense({units: 64, activation: 'relu', inputShape: [63]}));
        model.add(tf.layers.dropout({rate: 0.2}));
        model.add(tf.layers.dense({units: 32, activation: 'relu'}));
        model.add(tf.layers.dense({units: 4, activation: 'softmax'}));

        model.compile({optimizer: 'adam', loss: 'categoricalCrossentropy', metrics: ['accuracy']});

        await model.fit(inputs, labels, {
            epochs: 50,
            batchSize: 16,
            callbacks: {
                onEpochEnd: (e, l) => {
                    document.getElementById('status').innerText = `Epoch ${e}: Acc ${l.acc.toFixed(2)}`;
                }
            }
        });

        isTraining = false;
        document.getElementById('status').innerText = "Done!";
        document.getElementById('btn-save').disabled = false;
        inputs.dispose(); labels.dispose();
    }

    // --- –ü–ï–†–ï–î–ë–ê–ß–ï–ù–ù–Ø ---
    function predict(lm) {
        tf.tidy(() => {
            const input = tf.tensor2d([processLandmarks(lm)]);
            const pred = model.predict(input);
            const idx = pred.argMax(1).dataSync()[0];
            const conf = pred.dataSync()[idx];
            
            const txt = document.getElementById('prediction');
            txt.innerText = `${CLASSES[idx]} ${(conf*100).toFixed(0)}%`;
            txt.style.color = conf > 0.8 ? '#00ffcc' : '#555';
        });
    }

    // --- –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø ---
    async function download() {
        await model.save('downloads://gesture-model');
    }
</script>
</body>
</html>

